defaults:
  - data/corpus: e2e
  - data/preprocessing: tgen
  - _self_

random_seed: 42

pytorch:
  device: cpu

model:
  name: tgen
  max_input_length: 30
  encoder:
    embeddings:
      type: torch
      embedding_dim: 50
      backprop: True
    cell: lstm
    num_hidden_dims: 128
  decoder:
    embeddings:
      type: torch
      embedding_dim: 50
      backprop: True
      padding_idx: 0
      start_idx: 1
      stop_idx: 2
    cell: lstm
    num_hidden_dims: 128

mode: train

train:
  num_epochs: 20
  record_interval: 1000
  shuffle: True
  batch_size: 1 # TGen used 20
  optimizer: adam
  learning_rate: 0.0005
  learning_rate_decay: 0.5 # TGen used 0.0
  train_splits: [train]
  dev_splits: [dev]

test:
  generator_file: trained-tgen-model.pt
  classifier_file: models/e2e.semclassifier.nlg.tgz
  test_splits: [test]
